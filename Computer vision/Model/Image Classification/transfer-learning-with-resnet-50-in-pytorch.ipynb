{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"e7397945384193360b50e41b8052a3292d1db75f","id":"Wx_WrFZfSADk"},"outputs":[],"source":["import numpy as np\n","# %matplotlib inline\n","import matplotlib.pyplot as plt\n","from PIL import Image"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"eb72fac76d6d250a6f63644340e443941a0ec802","id":"BbXj8nTxSADl"},"outputs":[],"source":["import torch\n","from torchvision import datasets, models, transforms\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"7554266c3a0deabe52ae18973ca6b78a468f9d3f","id":"0iD8WIfwSADl","outputId":"ade053e3-c42b-4a36-dc57-fdfeadf08da3"},"outputs":[{"data":{"text/plain":["'2.4.1+cu124'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.__version__  # should be 0.4.1"]},{"cell_type":"code","execution_count":4,"metadata":{"_uuid":"871565acaaacbc7493fd933f34cab7c376174ecd","id":"ZfvvrVTXSADm","outputId":"ba9acde9-3309-4099-cc45-cdccee76ae55"},"outputs":[{"data":{"text/plain":["'0.19.1+cu124'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torchvision\n","torchvision.__version__  # should be 0.2.1"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":6,"metadata":{"_uuid":"2f247ad045631f12116206e89fa30124c780f60a","id":"NMvZ6u9xSADm"},"outputs":[],"source":["# Kaggle Kernel-dependent\n","input_path = \"./datasets/\""]},{"cell_type":"markdown","metadata":{"_uuid":"6090f5938db4e9685fc563b3ad6bd5adbd8f0bb7","id":"McwsEtoWSADm"},"source":["### 2. Create PyTorch data generators"]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"124e10a366db88235fc7a5716e791811cd202193","id":"USfry2fdSADm"},"outputs":[],"source":["normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","\n","data_transforms = {\n","    'train':\n","    transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize\n","    ]),\n","    'val':\n","    transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.ToTensor(),\n","        normalize\n","    ]),\n","}\n","\n","image_datasets = {\n","    'train':\n","    datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n","    'val':\n","    datasets.ImageFolder(input_path + 'val', data_transforms['val'])\n","}\n","\n","dataloaders = {\n","    'train':\n","    torch.utils.data.DataLoader(image_datasets['train'],\n","                                batch_size=32,\n","                                shuffle=True,\n","                                num_workers=0),  # for Kaggle\n","    'val':\n","    torch.utils.data.DataLoader(image_datasets['val'],\n","                                batch_size=32,\n","                                shuffle=False,\n","                                num_workers=0)  # for Kaggle\n","}"]},{"cell_type":"markdown","metadata":{"_uuid":"8e7d47a80fc9ae7e12ecde786ecd8df2ff4fc11e","id":"fgcch1PISADn"},"source":["### 3. Create the network"]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"578892606f97f55335ee9954add8f71ff9a935c8","id":"3I4Db46aSADn","outputId":"70a78ca0-fe15-4aa7-fc56-b94e839158ab"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"776b85eaacbb1b53c5bb1e03abfb45d12b639db4","id":"t17m9zCASADn","outputId":"43d3fb60-5c26-4a4f-9a0b-bb87cc177f24"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sirip\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\sirip\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["# model = models.resnet50(pretrained=True).to(device)\n","\n","# for param in model.parameters():\n","#     param.requires_grad = False\n","\n","# model.fc = nn.Sequential(\n","#                nn.Linear(2048, 128),\n","#                nn.ReLU(inplace=True),\n","#                nn.Linear(128, 2)).to(device)\n","\n","model = models.resnet50(pretrained=True).to(device)\n","\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","model.fc = nn.Sequential(\n","    nn.Linear(2048, 128),\n","    nn.ReLU(inplace=True),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 2)\n",").to(device)\n","\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"01e7701173952cefb75cb0028179ca65f71feb30","id":"dx7D9DJFSADn"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.fc.parameters(),lr = 0.001)"]},{"cell_type":"markdown","metadata":{"_uuid":"11748461db9eac06eecf1fa9fd30f07eebf16025","id":"yZe4O4eNSADn"},"source":["### 4. Train the model"]},{"cell_type":"code","execution_count":11,"metadata":{"_uuid":"9362fa736de086d3610a096c761c29a7117033fd","id":"3MLVk_unSADn"},"outputs":[],"source":["def train_model(model, criterion, optimizer, num_epochs=3):\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                if phase == 'train':\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                _, preds = torch.max(outputs, 1)\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(image_datasets[phase])\n","            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n","\n","            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n","                                                        epoch_loss,\n","                                                        epoch_acc))\n","    return model"]},{"cell_type":"markdown","metadata":{"_uuid":"e3d926cb6f1406d70e5cbdcca1ce199e660a9c80","id":"TnmnECB8SADo"},"source":["There is some error (even though the same version work on my own computer):\n","\n","> RuntimeError: DataLoader worker (pid 56) is killed by signal: Bus error. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n","> RuntimeError: DataLoader worker (pid 59) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n","\n","See [this issue](https://github.com/pytorch/pytorch/issues/5301) and [that thread](https://discuss.pytorch.org/t/dataloader-randomly-crashes-after-few-epochs/20433/2). Setting `num_workers=0` in `DataLoader` solved it."]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"476b5d6e0a91a2fefd2a1803437674148f526182","id":"FIUamr4ySADo","outputId":"0c2c61a7-52c4-4418-edef-63a446e11523"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","----------\n","train loss: 0.1814, acc: 0.9251\n","val loss: 0.0485, acc: 0.9823\n","Epoch 2/10\n","----------\n","train loss: 0.1056, acc: 0.9601\n","val loss: 0.0431, acc: 0.9841\n","Epoch 3/10\n","----------\n","train loss: 0.0847, acc: 0.9689\n","val loss: 0.0292, acc: 0.9903\n","Epoch 4/10\n","----------\n","train loss: 0.0729, acc: 0.9727\n","val loss: 0.0208, acc: 0.9938\n","Epoch 5/10\n","----------\n","train loss: 0.0728, acc: 0.9742\n","val loss: 0.0152, acc: 0.9947\n","Epoch 6/10\n","----------\n","train loss: 0.0753, acc: 0.9726\n","val loss: 0.0301, acc: 0.9903\n","Epoch 7/10\n","----------\n","train loss: 0.0678, acc: 0.9748\n","val loss: 0.0189, acc: 0.9947\n","Epoch 8/10\n","----------\n","train loss: 0.0590, acc: 0.9779\n","val loss: 0.0163, acc: 0.9965\n","Epoch 9/10\n","----------\n","train loss: 0.0604, acc: 0.9782\n","val loss: 0.0125, acc: 0.9947\n","Epoch 10/10\n","----------\n","train loss: 0.0501, acc: 0.9820\n","val loss: 0.0129, acc: 0.9938\n"]}],"source":["model_trained = train_model(model, criterion, optimizer, num_epochs=10)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=2048, out_features=128, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=128, out_features=2, bias=True)\n","  )\n",")\n"]}],"source":["print(model_trained)"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"a423f25ece8d2f2baf4f1c3b8f4adc4118f750a5","id":"h_47a0gqSADo"},"outputs":[],"source":["torch.save(model_trained.state_dict(), 'models/weightsV4.h5')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\sirip\\AppData\\Local\\Temp\\ipykernel_12992\\2677868803.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('models/weightsV3.h5'), strict=False)\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('models/weightsV3.h5'), strict=False)"]},{"cell_type":"markdown","metadata":{"_uuid":"c0606791b4a53b63fd624bc2670c8e0f3dd7a5af","id":"uVqYICBFSADo"},"source":["### 5. Save and load the model"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"141db7f7ac8f64bf9d59ac770e60d77af938a799","id":"I9YqpqJ7SADo","outputId":"4c612e59-72cd-4593-b193-6dcd25d0a4dc"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\PlsDontBroken\\anaconda3\\envs\\yolov5\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","C:\\Users\\PlsDontBroken\\anaconda3\\envs\\yolov5\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model = models.resnet50(pretrained=None).to(device)\n","model.fc = nn.Sequential(\n","               nn.Linear(2048, 128),\n","               nn.ReLU(inplace=True),\n","               nn.Linear(128, 2)).to(device)\n","model.load_state_dict(torch.load('models/pytorch/weights.h5'))"]},{"cell_type":"markdown","metadata":{"_uuid":"e9e3f868d5d63b611db4c330ed91e4c724b62fa5","id":"jQi_jRPBSADo"},"source":["### 6. Make predictions on sample test images"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0f066f71893e37a99fee4960e05802dde822931e","id":"g3DghdSpSADo"},"outputs":[],"source":["validation_img_paths = [\"test/non-target/cassava_healthy_118.jpg\",\n","                                   \"test/target/Collecto_733.jpg\",\n","                                   \"test/non-target/image_809.jpg\",\n","                                    \"test/target/healthy_959.jpg\",\n","                                    \"test/target/other_diseases_360.jpg\"]\n","\n","img_list = [Image.open(input_path + img_path) for img_path in validation_img_paths]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUst0SWPSADo","scrolled":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqP9sXB1SADo"},"outputs":[],"source":["# transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5f7a7ebace882d1964835fad2dfaa237658788ef","id":"HPuEf4QVSADo","scrolled":true},"outputs":[],"source":["validation_batch = torch.stack([data_transforms['val'](img).to(device)\n","                                for img in img_list])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0adf2365151ece899007672d110a1e81e3a81e39","id":"zd4VyDbVSADo","outputId":"9bc71eb3-c44d-4ae0-c130-cd5fb8bc6a95"},"outputs":[{"data":{"text/plain":["tensor([[ 2.7856, -1.4965],\n","        [-2.6797,  3.1765],\n","        [ 7.6006, -5.6845],\n","        [-5.7725,  5.8981],\n","        [-2.0434,  2.4601]], device='cuda:0', grad_fn=<AddmmBackward0>)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["pred_logits_tensor = model(validation_batch)\n","pred_logits_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8a090957e80889d66a31f4817c3d5cbc7a9f8554","id":"hc4AzBPmSADo","outputId":"3c6a68cc-b1dc-4862-dc5b-947cf600bb36","scrolled":true},"outputs":[{"data":{"text/plain":["array([[9.8637474e-01, 1.3625237e-02],\n","       [2.8539165e-03, 9.9714607e-01],\n","       [9.9999833e-01, 1.6996580e-06],\n","       [8.5411875e-06, 9.9999142e-01],\n","       [1.0949642e-02, 9.8905039e-01]], dtype=float32)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["pred_probs = F.softmax(pred_logits_tensor , dim=1).cpu().data.numpy()\n","pred_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f7068e5065cc37985e4b6ed7cdb32916cfccf04c","id":"R-UvH681SADo","outputId":"55933b16-9f40-4615-8d45-f114371d9d56"},"outputs":[{"data":{"text/plain":["array([0, 1, 0, 1, 1], dtype=int64)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["ans = np.argmax(pred_probs, axis=1)\n","ans"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ad8b90e800bb77317b3b58987d6461f1f91f5d41","id":"q8zeiE_nSADo"},"outputs":[],"source":["validation_img_paths = \"test/non-target/cassava_healthy_118.jpg\"\n","\n","img_list = Image.open(input_path + validation_img_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qcZ5aqMSADp"},"outputs":[],"source":["validation_batch=transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),normalize])(img_list).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bp2aY28oSADp"},"outputs":[],"source":["pred_logits_tensor = model(validation_batch.unsqueeze(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sAmyhCGoSADp"},"outputs":[],"source":["pred_probs = F.softmax(pred_logits_tensor , dim=1).cpu().data.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mB59AH5LSADp","outputId":"03b7b90d-6855-4058-c625-cbdd0036e97b"},"outputs":[{"data":{"text/plain":["array([[0.07103631, 0.92896366]], dtype=float32)"]},"execution_count":174,"metadata":{},"output_type":"execute_result"}],"source":["pred_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_zFfZOOSADp"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":56851,"sourceId":109319,"sourceType":"datasetVersion"}],"dockerImageVersionId":11105,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"171px"},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"oldHeight":325,"position":{"height":"347px","left":"536px","right":"20px","top":"545px","width":"350px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"varInspector_section_display":"block","window_display":false}},"nbformat":4,"nbformat_minor":0}
